#!/bin/bash

# HealthAI Llama2 Setup Script
# This script sets up Llama2 locally using Ollama for the HealthAI platform

echo "ğŸš€ HealthAI Llama2 Setup Script"
echo "================================"

# Check if running on supported OS
if [[ "$OSTYPE" != "linux-gnu"* ]] && [[ "$OSTYPE" != "darwin"* ]]; then
    echo "âŒ This script currently supports Linux and macOS only"
    echo "For Windows, please visit https://ollama.ai/ for manual installation"
    exit 1
fi

echo "ğŸ“‹ Checking system requirements..."

# Check if curl is available
if ! command -v curl &> /dev/null; then
    echo "âŒ curl is required but not installed. Please install curl first."
    exit 1
fi

# Check available disk space (need at least 4GB for Llama2 7B)
available_space=$(df -h . | awk 'NR==2 {print $4}' | sed 's/G//')
if [[ $available_space -lt 4 ]]; then
    echo "âš ï¸  Warning: Less than 4GB free space available. Llama2 7B model requires ~3.8GB"
    read -p "Continue anyway? (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        exit 1
    fi
fi

echo "âœ… System requirements check passed"

# Install Ollama
echo "ğŸ“¦ Installing Ollama..."
if command -v ollama &> /dev/null; then
    echo "âœ… Ollama is already installed"
    ollama --version
else
    echo "â¬‡ï¸  Downloading and installing Ollama..."
    curl -fsSL https://ollama.ai/install.sh | sh
    
    if [ $? -eq 0 ]; then
        echo "âœ… Ollama installed successfully"
    else
        echo "âŒ Failed to install Ollama"
        exit 1
    fi
fi

# Start Ollama service
echo "ğŸ”„ Starting Ollama service..."
if pgrep -x "ollama" > /dev/null; then
    echo "âœ… Ollama service is already running"
else
    echo "ğŸš€ Starting Ollama service in background..."
    nohup ollama serve > ollama.log 2>&1 &
    
    # Wait for service to start
    sleep 3
    
    if pgrep -x "ollama" > /dev/null; then
        echo "âœ… Ollama service started successfully"
    else
        echo "âŒ Failed to start Ollama service"
        echo "Check ollama.log for details"
        exit 1
    fi
fi

# Pull Llama2 model
echo "ğŸ§  Downloading Llama2 7B model (this may take a while)..."
ollama pull llama2:7b

if [ $? -eq 0 ]; then
    echo "âœ… Llama2 7B model downloaded successfully"
else
    echo "âŒ Failed to download Llama2 model"
    exit 1
fi

# Test the installation
echo "ğŸ§ª Testing Llama2 installation..."
test_response=$(curl -s -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d '{"model": "llama2:7b", "prompt": "Hello, are you working?", "stream": false}')

if [[ $test_response == *"response"* ]]; then
    echo "âœ… Llama2 is working correctly!"
else
    echo "âŒ Llama2 test failed"
    echo "Response: $test_response"
    exit 1
fi

# Create configuration file
echo "âš™ï¸  Creating configuration file..."
cat > config/llama2.local.js << EOF
// Local Llama2 Configuration
// This file is auto-generated by setup-llama2.sh

export const localLlama2Config = {
  api: {
    local: {
      baseUrl: 'http://localhost:11434',
      model: 'llama2:7b',
      endpoint: '/api/generate',
      enabled: true,
      tested: true,
      installedAt: '$(date -u +"%Y-%m-%dT%H:%M:%SZ")'
    }
  },
  
  status: {
    installed: true,
    model: 'llama2:7b',
    service: 'ollama',
    version: '$(ollama --version 2>/dev/null | head -n1 || echo "unknown")'
  }
};

// Test function
export async function testLocalLlama2() {
  try {
    const response = await fetch('http://localhost:11434/api/generate', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        model: 'llama2:7b',
        prompt: 'Test message',
        stream: false
      })
    });
    
    return response.ok;
  } catch (error) {
    return false;
  }
}
EOF

echo "âœ… Configuration file created at config/llama2.local.js"

# Create service management script
echo "ğŸ› ï¸  Creating service management script..."
cat > manage-llama2.sh << 'EOF'
#!/bin/bash

# HealthAI Llama2 Service Management Script

case "$1" in
    start)
        echo "ğŸš€ Starting Ollama service..."
        if pgrep -x "ollama" > /dev/null; then
            echo "âœ… Ollama is already running"
        else
            nohup ollama serve > ollama.log 2>&1 &
            sleep 2
            if pgrep -x "ollama" > /dev/null; then
                echo "âœ… Ollama started successfully"
            else
                echo "âŒ Failed to start Ollama"
            fi
        fi
        ;;
    stop)
        echo "ğŸ›‘ Stopping Ollama service..."
        pkill -x ollama
        echo "âœ… Ollama stopped"
        ;;
    status)
        if pgrep -x "ollama" > /dev/null; then
            echo "âœ… Ollama is running"
            echo "ğŸ“Š Service details:"
            ps aux | grep ollama | grep -v grep
        else
            echo "âŒ Ollama is not running"
        fi
        ;;
    test)
        echo "ğŸ§ª Testing Llama2..."
        response=$(curl -s -X POST http://localhost:11434/api/generate \
            -H "Content-Type: application/json" \
            -d '{"model": "llama2:7b", "prompt": "Hello", "stream": false}')
        
        if [[ $response == *"response"* ]]; then
            echo "âœ… Llama2 is working correctly"
        else
            echo "âŒ Llama2 test failed"
        fi
        ;;
    logs)
        echo "ğŸ“‹ Ollama logs:"
        tail -f ollama.log
        ;;
    *)
        echo "Usage: $0 {start|stop|status|test|logs}"
        echo ""
        echo "Commands:"
        echo "  start   - Start Ollama service"
        echo "  stop    - Stop Ollama service"
        echo "  status  - Check service status"
        echo "  test    - Test Llama2 functionality"
        echo "  logs    - View service logs"
        exit 1
        ;;
esac
EOF

chmod +x manage-llama2.sh
echo "âœ… Service management script created: ./manage-llama2.sh"

# Update package.json scripts
if [ -f package.json ]; then
    echo "ğŸ“¦ Updating package.json scripts..."
    # Add Llama2 management scripts to package.json
    node -e "
    const fs = require('fs');
    const pkg = JSON.parse(fs.readFileSync('package.json', 'utf8'));
    pkg.scripts = pkg.scripts || {};
    pkg.scripts['llama2:start'] = './manage-llama2.sh start';
    pkg.scripts['llama2:stop'] = './manage-llama2.sh stop';
    pkg.scripts['llama2:status'] = './manage-llama2.sh status';
    pkg.scripts['llama2:test'] = './manage-llama2.sh test';
    fs.writeFileSync('package.json', JSON.stringify(pkg, null, 2));
    " 2>/dev/null || echo "âš ï¸  Could not update package.json (Node.js not available)"
fi

echo ""
echo "ğŸ‰ Llama2 setup completed successfully!"
echo ""
echo "ğŸ“‹ Next steps:"
echo "1. The HealthAI application will now use Llama2 for AI responses"
echo "2. Ollama service is running in the background"
echo "3. Use './manage-llama2.sh status' to check service status"
echo "4. Use './manage-llama2.sh test' to test functionality"
echo ""
echo "ğŸ”§ Service management:"
echo "â€¢ Start service: ./manage-llama2.sh start"
echo "â€¢ Stop service:  ./manage-llama2.sh stop"
echo "â€¢ Check status:  ./manage-llama2.sh status"
echo "â€¢ View logs:     ./manage-llama2.sh logs"
echo ""
echo "ğŸ“š Documentation: docs/LLAMA2_INTEGRATION.md"
echo ""
echo "ğŸš€ You can now start the HealthAI application and enjoy AI-powered health assistance!"

